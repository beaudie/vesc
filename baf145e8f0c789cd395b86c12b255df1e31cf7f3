{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "274d898f_2dc901a1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-10-29T17:12:49Z",
      "side": 1,
      "message": "Igor, I apologize I haven\u0027t found the time to review this change yet.\n\nHave you seen the bottom of this commit message? https://chromium-review.googlesource.com/c/angle/angle/+/5006874/6//COMMIT_MSG\n\nI thought about this in the past, I was always a little worried that we\u0027d be implementing a scheduler on top of the OS scheduler and be swamped with complexity and weird behavior because of it.\n\nI am fully aware of the problem, just unsure of the best solution. So I have two asks here:\n\n1. I have a benchmark for this I\u0027ve used in the past: https://chromium-review.googlesource.com/c/angle/angle/+/4859584/ You can see the tasks in perfetto which helps visualize exactly what\u0027s going on and how well the algorithm is working. I assume you also have something you\u0027ve been testing against. How much does this improve things compared with ToT? For my benchmark, I\u0027d easily imagine ~33% reduction in frame time, but it would be good to have an exact measure (verified with a perfetto trace).\n\n2. If instead of all of this, we\u0027d just multiply `mDesiredThreadCount` by 1.5 in ToT of ANGLE, how much do we gain in the same benchmarks? My reasoning for this is that we\u0027d use more threads than there are CPUs, but knowing the link-waits-for-two-compiles pattern, a third of the tasks are blocked, and the rest constitute 100% of the CPUs.\n\nMy hope is that the +50% threads solution gets us close enough to the performance of what you have and we can live with a much simpler implementation.",
      "revId": "baf145e8f0c789cd395b86c12b255df1e31cf7f3",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e4ed8be3_3248fb93",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1564492
      },
      "writtenOn": "2024-10-29T17:59:31Z",
      "side": 1,
      "message": "\u003e Have you seen the bottom of this commit message?\n\nYes, I have. In the past and then another time before implementing this.\n\n\u003e I thought about this in the past, I was always a little worried that \nwe\u0027d be implementing a scheduler on top of the OS scheduler and be \nswamped with complexity and weird behavior because of it.\n\nUsing dependency is not mandatory.\nAlso my commits do not change how pools are used in the code.\n\nBut what is complex now?\nWe are already starting tasks from other tasks, but now it will be optimized with dependencies.\nWe will fix problem waiting for shaders in a clean way...\n\u003e How much does this improve things compared with ToT?\n\nI do not have such tests. Also it is hard to make good test. What we need to measure?\n\nI will try to look at your tests, but is there a point?\nIt is look like you already decided to not merge this. Sorry, but I\u0027m tired refactoring from Roman\u0027s suggestions...\n\nI will try to run your tests after I finish...\n\n\u003e For my benchmark, I\u0027d easily imagine ~33% reduction in frame time, but \nit would be good to have an exact measure (verified with a perfetto \ntrace).\n\nTo see differences from my commits need to start using dependencies between tasks. Until then - no significant changes expected.\n\nI implemented this not only to improve the current situation, but to have such functionality available. You are free to ignore dependencies. I\u0027m planning to use it for my own experiments, but remembered, that it might be useful for the current code (probably a mistake)...\n\n\u003e If instead of all of this, we\u0027d just multiply mDesiredThreadCount\n by 1.5 in ToT of ANGLE, how much do we gain in the same benchmarks? My \nreasoning for this is that we\u0027d use more threads than there are CPUs, \nbut knowing the link-waits-for-two-compiles pattern, a third of the \ntasks are blocked, and the rest constitute 100% of the CPUs.\n\nImplementation reason was not to fix specific problem when waiting on shaders in the link task.\n\nWith dependencies we can chain tasks, so that we are not utilizing all threads (create a background thread). For example, we can chain new `CreateMonolithicPipelineTask` to the previous, essentially creating single thread that will compile monolithic pipelines. This can be done manually, but this will require implementing some monolithic pipeline task queue.\n\nIn my work, I wanted to create multiple threads, that will run different stages of the same task. For example pipeline compilation can be divided: load shaders and pipeline data from disk, compiling shader modules, create pipeline. Each this sub-task may be done in different threads. So these threads will act like conveyor stages. But again, we will not load all the available threads. No need to implement scheduling functionality, but rather concentrate on implementing the sub-tasks.\n\nOther part is that we have a `TaskDependencyHint::SubTask`, that will execute sub-task in the same thread as the parent task. Currently this is impossible. When Parent task starts sub-task it itself still running, so the new thread will be started for the sub-task.\n\nWhile I do not have benchmarks, I did quick tests. And simply posting empty tasks runs faster using new implementation than the ToT, because of free thread tracking and avoiding to call `notify_one` unnecessarily (even without any dependencies).\n\n\u003e My hope is that the +50% threads solution gets us close enough to the \nperformance of what you have and we can live with a much simpler \nimplementation.\n\nAgain. Dependency not to fix single problem, but to provide functionality, that may be used for other problems.\n\nTo see if this will work on practice or not, need to have the functionality first (which I do not have).\n\nWe can always stop using dependencies and revert the changes.\n\nI think, that we wasting too much time thinking how scary and complex everything is, instead of trying to understand it...",
      "parentUuid": "274d898f_2dc901a1",
      "revId": "baf145e8f0c789cd395b86c12b255df1e31cf7f3",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}