{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "7f56b9e3_a06e2572",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1329751
      },
      "writtenOn": "2021-06-22T12:48:14Z",
      "side": 1,
      "message": "LGTM, I thought Ninja already did this?",
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e528a5e8_87a2a896",
        "filename": "src/tests/capture_replay_tests.py",
        "patchSetId": 1
      },
      "lineNbr": 303,
      "author": {
        "id": 1329751
      },
      "writtenOn": "2021-06-22T12:56:44Z",
      "side": 1,
      "message": "This is what autoninja.py does here:\n\nnum_cores \u003d multiprocessing.cpu_count()\n\n  else:\n    j_value \u003d num_cores\n    # Ninja defaults to |num_cores + 2|\n    j_value +\u003d int(os.environ.get(\u0027NINJA_CORE_ADDITION\u0027, \u00272\u0027))\n    args.append(\u0027-j\u0027)\n    args.append(\u0027%d\u0027 % j_value)\n\nhttps://source.chromium.org/chromium/chromium/tools/depot_tools/+/main:autoninja.py;l\u003d1?q\u003dautoninja.py\u0026sq\u003d\u0026ss\u003dchromium\n\nSo if you preferred having fewer cores in use you could set NINJA_CORE_ADDITION locally.",
      "range": {
        "startLine": 301,
        "startChar": 0,
        "endLine": 303,
        "endChar": 0
      },
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "479059c9_33fcadde",
        "filename": "src/tests/capture_replay_tests.py",
        "patchSetId": 1
      },
      "lineNbr": 303,
      "author": {
        "id": 1491823
      },
      "writtenOn": "2021-06-22T13:29:50Z",
      "side": 1,
      "message": "OOH the capture_replay script does call ninja directly (one could change this), and, OTOH and more importantly, the scrip spawns a number of ninja processes that all use the same limit which is currently the number of cores, and since they don\u0027t know anything about each other, one can get e.g. eight batches on an eight core machine which leads to 64 compile processes. \n\nNow even if there was a value like NINJA_CORE_ADDITION, one wouldn\u0027t know what would be a sensible value, because it is not clear from the start how many batches will be created, and hence, how many ninja processes are started.\n\nBy using the \"-l\" parameter ninja only spawns new processes if the load is not higher than the given value, with that one can keep the number of compile processes on a manageable level without knowing how many batches might be created.",
      "parentUuid": "e528a5e8_87a2a896",
      "range": {
        "startLine": 301,
        "startChar": 0,
        "endLine": 303,
        "endChar": 0
      },
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "85fb97ef_46297992",
        "filename": "src/tests/capture_replay_tests.py",
        "patchSetId": 1
      },
      "lineNbr": 303,
      "author": {
        "id": 1329751
      },
      "writtenOn": "2021-06-25T21:14:22Z",
      "side": 1,
      "message": "I also found this:\n\n# A large build (with or without goma) tends to hog all system resources.\n# Launching the ninja process with \u0027nice\u0027 priorities improves this situation.\nprefix_args \u003d []\nif (sys.platform.startswith(\u0027linux\u0027)\n    and os.environ.get(\u0027NINJA_BUILD_IN_BACKGROUND\u0027, \u00270\u0027) \u003d\u003d \u00271\u0027):\n  # nice -10 is process priority 10 lower than default 0\n  # ionice -c 3 is IO priority IDLE\n  prefix_args \u003d [\u0027nice\u0027] + [\u0027-10\u0027]\n\nMaybe we should add a parameter for \"nice\" builds.",
      "parentUuid": "479059c9_33fcadde",
      "range": {
        "startLine": 301,
        "startChar": 0,
        "endLine": 303,
        "endChar": 0
      },
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7a5689bb_481d4786",
        "filename": "src/tests/capture_replay_tests.py",
        "patchSetId": 1
      },
      "lineNbr": 303,
      "author": {
        "id": 1491823
      },
      "writtenOn": "2021-06-28T07:14:19Z",
      "side": 1,
      "message": "I don\u0027t think \"nice\" is the solution. It seems that by default MAX_JOBS is eight, that is by default at most eight ninja jobs are started, and each of these might spawn \"40 * number_of_cores\" compile processes (capped by some number on win an Darwin). On my work laptop  (8-core) this results in a maximum of 2560 compile processes that could be started (the number is probably much lower because of the actual number of files to be compiled, I\u0027ve seen 40+ compile jobs at once). In any case add to that limits in RAM (16GB), then no value of \"nice\" can make this behave nicely on this system, because the nice value doesn\u0027t change the number of processes started, only their priority, and if it starts to swap the bye-bye performance*. \n\nWith the \"-l\" parameter, ninja takes the actual system load into account, and simply doesn\u0027t fire up new compile processes if the system load is above the given limit, so one can optimize the number if active compile processes across ninja instance. Here one could probably tune a bit, and AFAIK the rule of thump is that one should use not more than \"nproc + 1\" compile processes.\n\n* With that discussion it would seem to make sense to limit the number of jobs simply to one on a lower spec machine, but if the replay tests don\u0027t need to compile many files (like only the trace files), then one wouldn\u0027t want to  limit the number of jobs like this, because one could still run some tests in parallel.",
      "parentUuid": "85fb97ef_46297992",
      "range": {
        "startLine": 301,
        "startChar": 0,
        "endLine": 303,
        "endChar": 0
      },
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "cf94aff0_1fbb6cd9",
        "filename": "src/tests/capture_replay_tests.py",
        "patchSetId": 1
      },
      "lineNbr": 303,
      "author": {
        "id": 1329751
      },
      "writtenOn": "2021-06-28T13:00:24Z",
      "side": 1,
      "message": "Ack, makes sense. LGTM.",
      "parentUuid": "7a5689bb_481d4786",
      "range": {
        "startLine": 301,
        "startChar": 0,
        "endLine": 303,
        "endChar": 0
      },
      "revId": "99e4de150a70f909370c0f7cf4bbcbf1f2d58e3b",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}