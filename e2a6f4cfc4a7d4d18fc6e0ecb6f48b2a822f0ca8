{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "295498c0_33e4b3b4",
        "filename": "/COMMIT_MSG",
        "patchSetId": 21
      },
      "lineNbr": 7,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-05-31T03:01:16Z",
      "side": 1,
      "message": "Is this still WIP?",
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "33259794_8eef4ceb",
        "filename": "src/libANGLE/ProgramExecutable.cpp",
        "patchSetId": 21
      },
      "lineNbr": 2615,
      "author": {
        "id": 1392020
      },
      "writtenOn": "2024-05-30T22:26:10Z",
      "side": 1,
      "message": "I am not convinced why we need batching at all. Can\u0027t you just call into backend directly (i.e, call mImplementation-\u003e*SetUniformFunc() directly without if(!mSupportsUniformBatching) check)? I think as long at you made sure all other parts of code are thread safe (things like observer notification, calling into other shared object etc), which I think your earlier CLs already handled, you should be good to remove the share lock. The only thing you need to make sure is Looking at VK backend, the only way this is this SetUniformFunc call will only access the uniform data. If you are unsure about the other backend is thread safe, you can still keep share lock for other backend.",
      "range": {
        "startLine": 2615,
        "startChar": 7,
        "endLine": 2615,
        "endChar": 76
      },
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "f3ee37b2_175b6a73",
        "filename": "src/libANGLE/ProgramExecutable.cpp",
        "patchSetId": 21
      },
      "lineNbr": 2615,
      "author": {
        "id": 1392020
      },
      "writtenOn": "2024-05-30T22:43:09Z",
      "side": 1,
      "message": "One thing maybe you can entertain with is to make ProgramExecutableVk::setUniformImpl() function const so that you ensure we are not modifying anything other than writing to the mDefaultUniformBlocks[shaderType].uniformData.data() (you will need to make exception to the pointer returned from data() so that you can write to it. I think you can use mutable keyword).",
      "parentUuid": "33259794_8eef4ceb",
      "range": {
        "startLine": 2615,
        "startChar": 7,
        "endLine": 2615,
        "endChar": 76
      },
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "22b8b8b8_37d8d74d",
        "filename": "src/libANGLE/ProgramExecutable.cpp",
        "patchSetId": 21
      },
      "lineNbr": 2615,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-05-31T02:58:23Z",
      "side": 1,
      "message": "\u003e If you are unsure about the other backend is thread safe, you can still keep share lock for other backend.\n\nThe other backends don\u0027t claim to be thread safe, there is no concern there.\n\n\u003e I am not convinced why we need batching at all\n\nIt\u0027s mostly to manage the complexity. It\u0027s easier to reason about the thread-safety if very little happens (as in, the uniform gets batched and the function exits, nothing more). You\u0027re probably right that calling into the backend is still going to be as thread-safe, but it\u0027s just harder to reason about it.\n\n\u003e you will need to make exception to the pointer returned from data() so that you can write to it. I think you can use mutable keyword\n\nFWIW, you can pass in a pointer to the member (from the non-const caller) to the const function (which might as well not be a member function anymore) so it can be manipulated without making it `mutable`.",
      "parentUuid": "f3ee37b2_175b6a73",
      "range": {
        "startLine": 2615,
        "startChar": 7,
        "endLine": 2615,
        "endChar": 76
      },
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "84cbe251_0b5e43e0",
        "filename": "src/libANGLE/ProgramExecutable.cpp",
        "patchSetId": 21
      },
      "lineNbr": 2615,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-05-31T03:01:16Z",
      "side": 1,
      "message": "Oh one more thing, I suspect batching may also end up performing better. Bunch of uniform calls happen without a virtual call to backend, then one call processes them all in one go (using cache-local data).",
      "parentUuid": "22b8b8b8_37d8d74d",
      "range": {
        "startLine": 2615,
        "startChar": 7,
        "endLine": 2615,
        "endChar": 76
      },
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "519a18e7_680436ab",
        "filename": "src/libANGLE/ProgramExecutable.cpp",
        "patchSetId": 21
      },
      "lineNbr": 2615,
      "author": {
        "id": 1531247
      },
      "writtenOn": "2024-05-31T13:52:42Z",
      "side": 1,
      "message": "Thanks. I will try to:\n1) Check where it is safe to just remove the lock, go ahead and do that.\n2) Benchmark this batching idea and see if it helps after (1)",
      "parentUuid": "84cbe251_0b5e43e0",
      "range": {
        "startLine": 2615,
        "startChar": 7,
        "endLine": 2615,
        "endChar": 76
      },
      "revId": "e2a6f4cfc4a7d4d18fc6e0ecb6f48b2a822f0ca8",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}