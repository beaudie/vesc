{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "a7de375a_2debff91",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1393148
      },
      "writtenOn": "2021-03-26T17:54:19Z",
      "side": 1,
      "message": "Please review. This patch uses thread pool to complete compression.\nI set thread count to 1 in patch now. Do you have any suggestion about that?\nHow does ANGLE choose running thread countï¼Ÿ(for example, in shader compiling)",
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "77ff5e8c_cc2e2160",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2021-03-29T16:06:51Z",
      "side": 1,
      "message": "+Etienne regarding worker threads",
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b014b85d_e2d8f7ab",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2516,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2021-03-29T16:06:51Z",
      "side": 1,
      "message": "You can pass in the gl::Context here instead, and then we should be able to use gl::Context::getWorkerThreadPool(). No need for a pool specifically for this.",
      "range": {
        "startLine": 2516,
        "startChar": 79,
        "endLine": 2516,
        "endChar": 88
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "55366ad9_685f3c76",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2516,
      "author": {
        "id": 1393148
      },
      "writtenOn": "2021-03-31T08:36:17Z",
      "side": 1,
      "message": "Thanks Shahbaz. I use Context::mThreadPool to replace the new created one in newest PatchSet. But I have a question about Context::mThreadPool.\nThe mMaxThreads of mThreadPool will be set to std::thread::hardware_concurrency() which is not 1 in my local test. It seems we can only make sure that the tasks are submitted in order, but we can\u0027t make sure the compressed data are stored in order. Is it possible that the task submitted later is completed earlier than the previous task, though the later task won\u0027t be smaller than the previous task?\nIf so, the pipeline cache data stored in blob cache may be replaced by the earlier data.",
      "parentUuid": "b014b85d_e2d8f7ab",
      "range": {
        "startLine": 2516,
        "startChar": 79,
        "endLine": 2516,
        "endChar": 88
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9acab512_13d03b0f",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2516,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2021-03-31T14:15:51Z",
      "side": 1,
      "message": "How about we simply check if the last task is done (isReady() I believe), and if it\u0027s not done, skip this round. So for example if the worker thread usually takes 1.5 seconds to finish, we end up actually storing the cache every 2 seconds (instead of the default 1s). If it\u0027s fast enough but there is an occasional hitch, we would just skip storing it every now and then.",
      "parentUuid": "55366ad9_685f3c76",
      "range": {
        "startLine": 2516,
        "startChar": 79,
        "endLine": 2516,
        "endChar": 88
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9561b132_8a55eb4d",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2516,
      "author": {
        "id": 1393148
      },
      "writtenOn": "2021-04-08T09:32:35Z",
      "side": 1,
      "message": "Thanks Shahbaz, I think it\u0027s a good way to ensure the compression tasks can be finished in order and decrease the waiting time when it\u0027s fast enough.",
      "parentUuid": "9acab512_13d03b0f",
      "range": {
        "startLine": 2516,
        "startChar": 79,
        "endLine": 2516,
        "endChar": 88
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7aa09878_c4204413",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2583,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2021-03-29T16:06:51Z",
      "side": 1,
      "message": "There\u0027s a threading bug here. This MemoryBuffer came from a pool (ScratchBuffer) and handing it off to a thread is not safe. I\u0027m not quite familiar with the scratch buffer, so maybe Jamie would have a better idea, but it looks to me like if a thread is to be used, the memory should be allocated separately and handed off to the thread (which would free it when done).",
      "range": {
        "startLine": 2583,
        "startChar": 66,
        "endLine": 2583,
        "endChar": 83
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2b082d88_f577a73b",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2583,
      "author": {
        "id": 1393148
      },
      "writtenOn": "2021-03-31T08:36:17Z",
      "side": 1,
      "message": "Hi Jamie, do you have any suggestion about the used MemoryBuffer ?",
      "parentUuid": "7aa09878_c4204413",
      "range": {
        "startLine": 2583,
        "startChar": 66,
        "endLine": 2583,
        "endChar": 83
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5277e87f_39431a3f",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2583,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2021-03-31T14:15:51Z",
      "side": 1,
      "message": "How about we go with a simple std::vector that gets std::move\u0027d into the thread?",
      "parentUuid": "2b082d88_f577a73b",
      "range": {
        "startLine": 2583,
        "startChar": 66,
        "endLine": 2583,
        "endChar": 83
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "2b2e1c91_63e7b987",
        "filename": "src/libANGLE/renderer/vulkan/RendererVk.cpp",
        "patchSetId": 1
      },
      "lineNbr": 2583,
      "author": {
        "id": 1393148
      },
      "writtenOn": "2021-04-08T09:32:35Z",
      "side": 1,
      "message": "I define pipelineCacheData as a normal memory buffer in the new patch to avoid insecurity:\n\"\nangle::MemoryBuffer *pipelineCacheData \u003d new angle::MemoryBuffer();\npipelineCacheData-\u003eresize(pipelineCacheSize)\n\"",
      "parentUuid": "5277e87f_39431a3f",
      "range": {
        "startLine": 2583,
        "startChar": 66,
        "endLine": 2583,
        "endChar": 83
      },
      "revId": "0c5f5f35006a33da44971762b1438f116612dd79",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}