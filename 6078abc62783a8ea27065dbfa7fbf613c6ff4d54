{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "fb22163b_38f268e6",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-04-12T14:34:38Z",
      "side": 1,
      "message": "Should there be an implicit `flush` here? I\u0027m guessing a bit here, but if this is similar to Vulkan\u0027s semaphore waits (i.e. the primary command buffer waits for the semaphore before executing), then this can lead to GPU bubbles at best (and deadlock perhaps too).\n\nLike, again thinking in GL/Vk terms (so sorry if it doesn\u0027t apply), if you have this:\n\n1. dispatch, dispatch, dispatch\n2. enqueue wait for event\n3. dispatch, dispatch, dispatch\n\nThen if this is reordering the wait to before the dispatches in step 1, they will be done later than they could be.",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8824ba3c_5f5b8841",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-12T20:40:08Z",
      "side": 1,
      "message": "\u003e Then if this is reordering the wait to before the dispatches in step 1, they will be done later than they could be.\n\nThis happens only if event(s) come from different queue or if its CPU-side user-event. Since we don\u0027t have fine-grain ability to only launch those cmds from that different queue, we need to `clFinish` that other queue before we launch our current queue here (since user enforced dependency there).\n\nThe user-event case is all CPU side, user has to call `clSetUserEventStatus` in order for user to update that event\u0027s status.",
      "parentUuid": "fb22163b_38f268e6",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e3cdb25f_a55faa2a",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-04-13T03:05:22Z",
      "side": 1,
      "message": "\u003e we need to clFinish that other queue before we launch our current queue here\n\nOk I clearly don\u0027t know the details of CL events here, but that sounds inefficient. You should be able to `clFlush` the other queue before this one, not `clFinish` ...",
      "parentUuid": "8824ba3c_5f5b8841",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "482f4bb1_65c9c5d5",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-15T17:27:40Z",
      "side": 1,
      "message": "\u003e You should be able to clFlush the other queue before this one\n\nMainly its a spec thing, we have to ensure all dependent commands are in the CL_COMPLETE state prior to submitting/running cmds in `this` queue.\n```\nevent_wait_list and num_events_in_wait_list \nspecify events that need to complete before this \nparticular command can be executed.\n```\nI think the inefficiency stems from our initial implementation here. Like if we were to use `VkEvents` as the synchronization primitive between CL command queues (i.e. VK command buffers), I think that would greatly improve things (fine-grain), we would be able to flush then. Only thing that was initially hazy in my mind was how it could handle OpenCL user-events, as these events are triggered CPU-side via `clSetUserEventStatus` - but it looks like VkEvents handle this case as well.\n\nDo we want to rework this CL (and perhaps prior CLs in relation chain) to do that, or should we mark a TODO here to revisit in the near-future? I\u0027m okay with either.",
      "parentUuid": "e3cdb25f_a55faa2a",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "65d1227f_ca24f5f7",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-04-15T17:47:19Z",
      "side": 1,
      "message": "Leave a TODO then, that looks like a big rework that could perhaps be done after conformance.",
      "parentUuid": "482f4bb1_65c9c5d5",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "0513a550_9adb7227",
        "filename": "src/libANGLE/renderer/vulkan/CLCommandQueueVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 399,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-15T20:18:31Z",
      "side": 1,
      "message": "Acknowledged",
      "parentUuid": "65d1227f_ca24f5f7",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "93aae0c4_49a6d638",
        "filename": "src/libANGLE/renderer/vulkan/CLContextVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 264,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-04-12T14:34:38Z",
      "side": 1,
      "message": "Shouldn\u0027t this wait for the event\u0027s serial instead?",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9996a82c_03523d5e",
        "filename": "src/libANGLE/renderer/vulkan/CLContextVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 264,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-12T20:40:08Z",
      "side": 1,
      "message": "As mentioned from parent CL\u0027s (flush/finish) comment, our current/initial implementation does not rely too much on serials (this can change in the future).\n\n`clWaitForEvents` is blocking call here. Given following example:\n```\ncl_events ndrEvents[2] \u003d { CL_QUEUED, CL_QUEUED };\nclEnqueueNDRangeKernel(..., ndrEvents[0]);\nclEnqueueNDRangeKernel(..., ndrEvents[1]);\n\nclWaitForEvents(2, ndrEvents);\n```\n\nIf we only just wait for event serial, we would block/timeout here since\nwe did not `clFinish` for that event\u0027s command queue.\nhttps://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_API.html#clWaitForEvents\n```\nThis function waits on the host thread for commands identified by event \nobjects in event_list to complete. A command is considered complete \nif its execution status is CL_COMPLETE or a negative value. \nThe events specified in event_list act as synchronization points.\n```\nCalling finish here is to guarantee event(s) attempt to get to that \n`CL_COMPLETE` state. (or some negative value if something went horribly wrong).",
      "parentUuid": "93aae0c4_49a6d638",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "96a135aa_a313185a",
        "filename": "src/libANGLE/renderer/vulkan/CLContextVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 264,
      "author": {
        "id": 1300114
      },
      "writtenOn": "2024-04-13T03:05:22Z",
      "side": 1,
      "message": "Right, that\u0027s where the \"wait for the event\u0027s serial\" actually comes in. Basically what we have a `finishQueueSerial` that waits until the commands up to a serial is finished. `clFinish` is basically `finishQueueSerial(lastSerial)`.\n\nTo re-iterate what I wrote in an earlier CL about `clFlush`, you _can_ actually have work associated with a submission to be done once we deem that submission finished (checked at various points, such as periodically or when a sync object is queried). See for example how `SyncHelper::getStatus` calls `renderer-\u003echeckCompletedCommands`. In that call, if serial N is finished, you can make sure the events associated with that submission are set to CL_COMPLETE.",
      "parentUuid": "9996a82c_03523d5e",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "20d808e5_93cc2420",
        "filename": "src/libANGLE/renderer/vulkan/CLContextVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 264,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-15T17:27:40Z",
      "side": 1,
      "message": "Agreed with your points. But going back to this API call, AFAIK `clWaitForEvents` essentially behaves like `clFinish` (only difference is that it can finish on multiple queues). At least this is our behavior in our current native OpenCL driver (technically we flush each event\u0027s queue, then wait on each event.\n\nActually, I think I see now. Are you saying we instead `clFlush` each event\u0027s queue, then wait for each event\u0027s serial object? If so, I think I\u0027m also on board with that - I can look into it today and try it out.",
      "parentUuid": "96a135aa_a313185a",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4fb0dcdc_a17edbe6",
        "filename": "src/libANGLE/renderer/vulkan/CLContextVk.cpp",
        "patchSetId": 20
      },
      "lineNbr": 264,
      "author": {
        "id": 1604617
      },
      "writtenOn": "2024-04-23T17:32:44Z",
      "side": 1,
      "message": "Hey @syoussefi@chromium.org - getting back to this. I tried looking into `Flush + ResourceUse wait`, however I\u0027m running into issues here. Since we launch `clFlush` on worker thread, we regularly hit case where we have not submitted yet when calling renderer wait routine shortly after (hitting asserts).\n\nI think once we make `clFlush` not use a submission thread and rather register post-fence ops + call submit commands, then I think we can go with this approach.\n\nTill then, is it reasonable to keep as-is and add a TODO here for this routine? I plan to rework all of this in the near future.",
      "parentUuid": "20d808e5_93cc2420",
      "revId": "6078abc62783a8ea27065dbfa7fbf613c6ff4d54",
      "serverId": "3ce6091f-6c88-37e8-8c75-72f92ae8dfba"
    }
  ]
}